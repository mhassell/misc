{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/39061354/scraping-youtube-playlist-video-links\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup \n",
    "import os\n",
    "from pytube import YouTube\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants \n",
    "nVideos = 5\n",
    "url='https://www.youtube.com/playlist?list=UU9-y-6csu5WGm29I7JiwpnA'\n",
    "path = '/Users/matthewhassell/Desktop'\n",
    "\n",
    "# parse the page here\n",
    "htmlParser = \"lxml\"\n",
    "html=urllib2.urlopen(url)\n",
    "response=html.read()\n",
    "soup=BeautifulSoup(response, htmlParser)\n",
    "links = soup.find_all('a', attrs={'class':'pl-video-title-link'})\n",
    "links = links[0:nVideos]   # get the most recent videos\n",
    "\n",
    "# is this even new?\n",
    "try:\n",
    "    lastVideoFile = open(\"lastVideos.txt\", \"r+b\")\n",
    "    lastFive = lastVideoFile.readlines()\n",
    "except IOError:\n",
    "    lastVideoFile = open(\"lastVideos.txt\", 'w')\n",
    "    lastFive = ''\n",
    "\n",
    "if lastFive == '':\n",
    "    for a in links:\n",
    "        lastVideoFile.write((a.get(\"href\")+'\\n'))\n",
    "    lastVideoFile.close()\n",
    "else:\n",
    "\t# find if we have any of these already\n",
    "\tfor j in range(nVideos):\n",
    "        found = False\n",
    "        for k in range(nVideos):\n",
    "            print links[j].get(\"href\") + '\\n'\n",
    "            print lastFive[k][:-1] + '\\n'\n",
    "            if links[j].get(\"href\") == lastFive[k][:-1]:\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "\t# these are the new ones\n",
    "\tlinks = links[0:j]\n",
    "\tlastFive = links + '\\n' + lastFive[k:]\n",
    "\n",
    "\t# take care of the file\n",
    "\tlastVideoFile.seek(0)\n",
    "\tlastVideoFile.write(lastFive)\n",
    "\tlastVideoFile.close()\n",
    "\n",
    "# now download the new ones\n",
    "for a in links:\n",
    "\tyt = YouTube('https://www.youtube.com' + a.get(\"href\"))\n",
    "\tvideo = yt.get('mp4', '360p')\n",
    "\tvideo.download(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-88048a8d24ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnVideos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"href\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlastFive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "for j in range(nVideos):\n",
    "        found = False\n",
    "        for k in range(nVideos):\n",
    "            if links[j].get(\"href\") == lastFive[k][:-1]:\n",
    "                found = True\n",
    "                break\n",
    "        if found:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup \n",
    "import os\n",
    "from pytube import YouTube\n",
    "\n",
    "# constants \n",
    "nVideos = 5\n",
    "url='https://www.youtube.com/playlist?list=UU9-y-6csu5WGm29I7JiwpnA'\n",
    "path = '/Users/matthewhassell/Desktop'\n",
    "\n",
    "# parse the page here\n",
    "htmlParser = \"lxml\"\n",
    "html=urllib2.urlopen(url)\n",
    "response=html.read()\n",
    "soup=BeautifulSoup(response, htmlParser)\n",
    "links = soup.find_all('a', attrs={'class':'pl-video-title-link'})\n",
    "links = links[0:nVideos]   # get the most recent videos\n",
    "\n",
    "# is this even new?\n",
    "try:\n",
    "    lastVideoFile = open(\"lastVideos.txt\", \"r+b\")\n",
    "    lastFive = lastVideoFile.readlines()\n",
    "except IOError:\n",
    "    lastVideoFile = open(\"lastVideos.txt\", 'w')\n",
    "    lastFive = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if lastFive == '':\n",
    "    for a in links:\n",
    "        lastVideoFile.write((a.get(\"href\")+'\\n'))\n",
    "    \n",
    "    lastVideoFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastFive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"pl-video-title-link yt-uix-tile-link yt-uix-sessionlink spf-link \" data-sessionlink=\"ei=66NzWfzpDMer8wTFtJ_4BA&amp;feature=plpp_video&amp;ved=CAcQxjQYACITCLyLz7_MndUCFcfVnAodRdoHTyj6LA\" dir=\"ltr\" href=\"/watch?v=QbSD4EtpVdY&amp;index=1&amp;list=UU9-y-6csu5WGm29I7JiwpnA\">\n",
      "      Now Hiring? (What Computing Companies Look For) - Computerphile\n",
      "    </a>\n",
      "<a class=\"pl-video-title-link yt-uix-tile-link yt-uix-sessionlink spf-link \" data-sessionlink=\"ei=66NzWfzpDMer8wTFtJ_4BA&amp;feature=plpp_video&amp;ved=CAgQxjQYASITCLyLz7_MndUCFcfVnAodRdoHTyj6LA\" dir=\"ltr\" href=\"/watch?v=rh7kpkwXnwA&amp;index=2&amp;list=UU9-y-6csu5WGm29I7JiwpnA\">\n",
      "      Reason for ARM (Acorn Archimedes at 30) - Computerphile\n",
      "    </a>\n",
      "<a class=\"pl-video-title-link yt-uix-tile-link yt-uix-sessionlink spf-link \" data-sessionlink=\"ei=66NzWfzpDMer8wTFtJ_4BA&amp;feature=plpp_video&amp;ved=CAkQxjQYAiITCLyLz7_MndUCFcfVnAodRdoHTyj6LA\" dir=\"ltr\" href=\"/watch?v=DyG9S9nAlUM&amp;index=3&amp;list=UU9-y-6csu5WGm29I7JiwpnA\">\n",
      "      Arrays vs Linked Lists - Computerphile\n",
      "    </a>\n",
      "<a class=\"pl-video-title-link yt-uix-tile-link yt-uix-sessionlink spf-link \" data-sessionlink=\"ei=66NzWfzpDMer8wTFtJ_4BA&amp;feature=plpp_video&amp;ved=CAoQxjQYAyITCLyLz7_MndUCFcfVnAodRdoHTyj6LA\" dir=\"ltr\" href=\"/watch?v=ZNrteLp_SvY&amp;index=4&amp;list=UU9-y-6csu5WGm29I7JiwpnA\">\n",
      "      Optical Character Recognition (OCR) - Computerphile\n",
      "    </a>\n",
      "<a class=\"pl-video-title-link yt-uix-tile-link yt-uix-sessionlink spf-link \" data-sessionlink=\"ei=66NzWfzpDMer8wTFtJ_4BA&amp;feature=plpp_video&amp;ved=CAsQxjQYBCITCLyLz7_MndUCFcfVnAodRdoHTyj6LA\" dir=\"ltr\" href=\"/watch?v=oKDPLAJiWQU&amp;index=5&amp;list=UU9-y-6csu5WGm29I7JiwpnA\">\n",
      "      Sun Server Restoration (Update) - Computerphile\n",
      "    </a>\n"
     ]
    }
   ],
   "source": [
    "for a in links:\n",
    "    print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<closed file 'lastVideos.txt', mode 'r+b' at 0x10b55d660>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastVideoFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lastVideoFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
